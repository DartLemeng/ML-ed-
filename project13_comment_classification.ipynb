{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c863231",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Функции-и-библиотеки\" data-toc-modified-id=\"Функции-и-библиотеки-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Функции и библиотеки</a></span></li><li><span><a href=\"#Обзор-данных\" data-toc-modified-id=\"Обзор-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обзор данных</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Предобработка данных</a></span></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#подготовка-признаков\" data-toc-modified-id=\"подготовка-признаков-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>подготовка признаков</a></span></li><li><span><a href=\"#BERT-(подготовка-признаков)\" data-toc-modified-id=\"BERT-(подготовка-признаков)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>BERT (подготовка признаков)</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li></ul></li><li><span><a href=\"#Финальное-тестирование\" data-toc-modified-id=\"Финальное-тестирование-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Финальное тестирование</a></span></li><li><span><a href=\"#Заключение\" data-toc-modified-id=\"Заключение-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Заключение</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb0735e",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. \n",
    "\n",
    "Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998e3e7",
   "metadata": {},
   "source": [
    "## Функции и библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6f66a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "import re \n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dacf91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->pymystem3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->pymystem3) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->pymystem3) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3 -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cc6413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from torch) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf0ec258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (4.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (4.10.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (1.18.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (2020.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda\\envs\\praktikum_env\\lib\\site-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b208b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) \n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17130cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target):\n",
    "      \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    fraction = round(len(target_ones)/len(target_zeros),2)\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d08a07",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10038782",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv ('D:/Data for projects/toxic_comments.csv')\n",
    "\n",
    "\n",
    "except: \n",
    "    df = pd.read_csv ('/datasets/toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d60ad210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9f00566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ca1d6",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4eadfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad787d",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281624d",
   "metadata": {},
   "source": [
    "### подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e259c6",
   "metadata": {},
   "source": [
    "вычислительных ресурсов моего компьютера не хватает для обработки всего датасета, по этому методом эксперимента мной определен мксимальный размер выборки на которой и будет проводится обучение моделей \n",
    "\n",
    "так же проведем балансировку целевых признаков в тренировочной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "898c8f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = np.random.RandomState(12345)\n",
    "batch = df.sample(frac=0.05, replace=False, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9fb03bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['text'], batch['toxic'] = downsample(batch['text'], batch['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd624d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    797\n",
       "0.0    790\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86db58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4b69732",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353a8b6",
   "metadata": {},
   "source": [
    "сформируем тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1a59d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, batch_test = train_test_split(batch, test_size=0.25, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93c0e11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch.reset_index(drop=True)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07b40954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test = batch_test.reset_index(drop=True)\n",
    "batch_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ded13142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    598\n",
       "0.0    592\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5aebc",
   "metadata": {},
   "source": [
    "из не задействованных данных соберу батч для тестирования модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfb84e",
   "metadata": {},
   "source": [
    "batch_test = df.sample(frac=0.002, replace=False, random_state=state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6e615",
   "metadata": {},
   "source": [
    "### BERT (подготовка признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2996976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa9de686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43603020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = batch['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4745b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = batch_test['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d6beb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [101, 2123, 2102, 2568, 2023, 5195, 21025, 210...\n",
       "1       [101, 2115, 28297, 1999, 2437, 3167, 8767, 200...\n",
       "2       [101, 1042, 1057, 1039, 1047, 1045, 1050, 1043...\n",
       "3       [101, 2175, 6616, 4426, 10931, 2304, 22673, 51...\n",
       "4       [101, 4364, 2066, 2017, 5754, 6977, 2033, 2061...\n",
       "                              ...                        \n",
       "1185    [101, 2023, 2003, 9951, 4998, 2013, 1996, 4431...\n",
       "1186    [101, 7592, 9587, 3406, 7592, 4875, 3654, 2100...\n",
       "1187    [101, 8185, 2964, 3718, 8185, 2964, 2013, 2023...\n",
       "1188    [101, 2500, 3188, 2000, 2008, 2051, 2323, 2022...\n",
       "1189    [101, 1040, 15922, 2006, 2251, 2106, 2017, 211...\n",
       "Name: text, Length: 1190, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "364db829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [101, 4433, 2316, 4681, 1045, 2031, 2787, 2000...\n",
       "1      [101, 2008, 1055, 5875, 2138, 1045, 2310, 4384...\n",
       "2      [101, 2023, 2079, 5051, 2003, 2108, 3825, 2000...\n",
       "3      [101, 1996, 2208, 2003, 2746, 2041, 2399, 1439...\n",
       "4      [101, 2251, 11396, 4067, 2017, 2097, 2228, 205...\n",
       "                             ...                        \n",
       "392    [101, 20948, 2065, 1057, 2123, 1056, 2113, 205...\n",
       "393    [101, 2026, 18006, 25380, 1045, 2001, 1999, 10...\n",
       "394    [101, 4638, 6300, 20255, 11721, 8524, 2099, 10...\n",
       "395    [101, 1037, 16983, 17906, 1055, 3193, 2339, 20...\n",
       "396    [101, 4283, 1045, 2064, 2156, 2009, 2003, 2006...\n",
       "Name: text, Length: 397, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "550f0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_list = []\n",
    "counter = 0\n",
    "for _ in tokenized:\n",
    "    if np.array(_).size >511:\n",
    "        counter_list.append(counter)\n",
    "    counter +=1\n",
    "    \n",
    "#counter_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c91fa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_list_test = []\n",
    "counter = 0\n",
    "for _ in tokenized_test:\n",
    "    if np.array(_).size >511:\n",
    "        counter_list_test.append(counter)\n",
    "    counter +=1\n",
    "    \n",
    "#counter_list_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3ded4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenized.drop(counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e5bf6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenized_test.drop(counter_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "884827e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = tokenized.apply(lambda x: np.array(x).size).max()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c114b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = tokenized_test.apply(lambda x: np.array(x).size).max()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d3b278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9d1fc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cdfd3074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1172, 495)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c7e8adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 494)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7b128c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded= padded.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "afe37676",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_test = padded_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66d1e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1172, 495)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0).astype('int64')\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09db2545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 494)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_test = np.where(padded_test != 0, 1, 0).astype('int64')\n",
    "attention_mask_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "810172a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "631050d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor(padded_test)  \n",
    "attention_mask_test = torch.tensor(attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62ed6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch['toxic'].drop(counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e779747",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = batch_test['toxic'].drop(counter_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10ff1172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38521a96e9654d19bc32b6390c5cec62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8h 36min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4ee65ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1518e13bcbf445e6a22f4253bd7ba7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(input_ids_test.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids_test[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask_test[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features_test = np.concatenate(embeddings)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b5be",
   "metadata": {},
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047f9dc",
   "metadata": {},
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844146a",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "12d8d656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels[:1150]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81894c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ab89505d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45e59b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368055555555556"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dce73bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8448844884488449"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.array(test_labels), lr_clf.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c245d",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f49ceefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785234899328859"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RFC = RandomForestClassifier(random_state=404, n_estimators=34) \n",
    "\n",
    "model_RFC.fit(train_features, train_labels) # обучение модели\n",
    "\n",
    "f1_score(np.array(test_labels), model_RFC.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57803bc5",
   "metadata": {},
   "source": [
    "## Финальное тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "234eead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = target_test[:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8da05d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.472 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c43a1d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352941176470587"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.array(target_test), lr_clf.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "410eb688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778115501519757"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.array(target_test), model_RFC.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b432c",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ba0a2",
   "metadata": {},
   "source": [
    "в рамках настоящего ислледования проведено обучение моделей (логистической регрессии и случайного леса) с использованием предобученной модели BERT для определения токсичных комментариев\n",
    "\n",
    "результаты метрики f1 для обеих моделей соответствуют требуемым - не меньше 0.75\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
